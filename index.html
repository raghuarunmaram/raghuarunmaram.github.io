<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Raghu Arun Maram - Data Engineer Portfolio</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;600&display=swap" rel="stylesheet">
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Raghu Arun Maram</h1>
            <p class="tagline">Data Engineer | AWS | 5+ Years Experience</p>
            <nav>
                <a href="#about">About</a> | 
                <a href="#skills">Skills</a> | 
                <a href="#projects">Projects</a> | 
                <a href="https://linkedin.com/in/raghuarunmaram">LinkedIn</a> | 
                <a href="mailto:raghuarun0912@gmail.com">Email</a>
            </nav>
        </div>
    </header>

    <section id="about" class="fade-in">
        <h2>About Me</h2>
        <p>I’m a seasoned Data Engineer with over 5 years of experience architecting robust, scalable data ecosystems. At Amazon Web Services (AWS), I spent 3 years crafting high-throughput pipelines using Kinesis, Glue, and Redshift, reducing latency by up to 40% for real-time analytics. Previously, at TCS, I optimized ETL workflows across 2 years, migrating terabyte-scale datasets to cloud platforms like Snowflake. I thrive on transforming complex raw data into actionable insights with cutting-edge cloud and big data technologies.</p>
    </section>

    <section id="skills" class="fade-in">
        <h2>Key Skills</h2>
        <div class="skills-grid">
            <div class="skill-card">
                <h3>AWS Ecosystem</h3>
                <p>S3 (Parquet), Redshift (SQL), Glue (Crawlers, Jobs), EMR (PySpark), SageMaker, CloudWatch, Lambda (Automation), Kinesis (Streams), DataSync, Athena, CloudFormation, Boto3</p>
            </div>
            <div class="skill-card">
                <h3>Programming & Scripting</h3>
                <p>Python (Pandas, Flask, Boto3), SQL (JOINs, Tuning), PySpark, YAML</p>
            </div>
            <div class="skill-card">
                <h3>Big Data Frameworks</h3>
                <p>Spark (ETL), Databricks (Delta Lake), HDFS</p>
            </div>
            <div class="skill-card">
                <h3>ETL & Pipelines</h3>
                <p>Glue (Event-Driven), Airflow, Fivetran, Matillion, Tableau Prep, Real-Time/Batch</p>
            </div>
            <div class="skill-card">
                <h3>Data Warehousing</h3>
                <p>Snowflake (Data Exchange), Redshift, SQL Server, Schema Modeling</p>
            </div>
            <div class="skill-card">
                <h3>Data Processing</h3>
                <p>DynamicFrames, Parquet, Validation, Optimization (30-50% Gains)</p>
            </div>
            <div class="skill-card">
                <h3>Analytics & BI</h3>
                <p>Tableau (Dashboards), Power BI, Athena (Insights)</p>
            </div>
            <div class="skill-card">
                <h3>Automation</h3>
                <p>Lambda (Scaling), Glue Triggers, Azure Data Factory, Airflow</p>
            </div>
            <div class="skill-card">
                <h3>Security</h3>
                <p>Encryption, IAM, Compliance</p>
            </div>
            <div class="skill-card">
                <h3>Database Expertise</h3>
                <p>Stored Procedures, Indexing, Query Tuning</p>
            </div>
        </div>
    </section>

    <section id="projects" class="fade-in">
        <h2>Projects</h2>
        <div class="project-card">
            <h3>Real-Time Sales Analytics Pipeline (Amazon Web Services)</h3>
            <p>Engineered a high-performance ETL pipeline to process 10TB/day of Amazon Ads transactional data, integrating real-time ingestion via AWS Kinesis Data Streams (handling 5M events/second) with AWS Glue for automated schema inference using Crawlers. Wrote Python scripts leveraging Boto3 and Pandas for multi-stage transformations, partitioning data into Parquet files stored in S3 for scalability. Loaded processed data into Redshift with optimized SQL queries (nested JOINs, window functions), slashing query latency by 40% and enabling 50+ business analysts to access near-real-time dashboards.</p>
            <p><strong>Tech:</strong> AWS Glue (Crawlers, Jobs), Amazon Redshift, Python (Pandas, Boto3), Amazon S3 (Parquet), SQL</p>
            <button class="details-btn">Details</button>
        </div>
        <div class="project-card">
            <h3>Data Migration for Legacy Systems (TCS)</h3>
            <p>Orchestrated the zero-downtime migration of 5TB of heterogeneous data from on-premises SQL Server databases to Snowflake, utilizing Apache Airflow for workflow automation and Python scripts for extracting data from REST APIs and flat files. Staged data in S3 buckets, transformed it with Snowflake’s native SQL functions (e.g., LATERAL FLATTEN for JSON), and optimized target schemas with indexing, achieving a 30% boost in query performance. Integrated the warehouse with Tableau, delivering interactive KPI dashboards to stakeholders.</p>
            <p><strong>Tech:</strong> SQL (SQL Server, Snowflake), Python, Apache Airflow, AWS S3, Snowflake, Tableau</p>
            <button class="details-btn">Details</button>
        </div>
    </section>

    <footer>
        <p>© 2025 Raghu Arun Maram. Hosted on GitHub Pages.</p>
    </footer>

    <script>
        // Fade-in on scroll
        const sections = document.querySelectorAll('.fade-in');
        const observer = new IntersectionObserver(entries => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.style.opacity = '1';
                    entry.target.style.transform = 'translateY(0)';
                }
            });
        }, { threshold: 0.2 });
    
        sections.forEach(section => {
            section.style.opacity = '0';
            section.style.transform = 'translateY(20px)';
            observer.observe(section);
        });
    
        // Toggle project details (placeholder)
        document.querySelectorAll('.details-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                const project = btn.parentElement;
                const details = project.querySelector('.project-details');
                if (!details) {
                    const newDetails = document.createElement('p');
                    newDetails.className = 'project-details';
                    newDetails.textContent = 'More details coming soon! Imagine an interactive demo here.';
                    newDetails.style.color = '#666';
                    project.appendChild(newDetails);
                } else {
                    details.style.display = details.style.display === 'none' ? 'block' : 'none';
                }
            });
        });
    </script>
</body>
</html>